import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Carregar o arquivo CSV
file_path = '/Users/hneto/OneDrive/Documentos/DataScientist/Notebooks/Sprint 8/users_behavior.csv'
data = pd.read_csv(file_path)

# Exibir informações gerais sobre o conjunto de dados
print(data.info())
print(data.head())

# Análise Exploratória dos Dados (EDA)
# Distribuição das variáveis numéricas
data.hist(bins=30, figsize=(15, 10))
plt.suptitle("Distribuição das Variáveis")
plt.show()

# Matriz de correlação
plt.figure(figsize=(10, 6))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title("Matriz de Correlação")
plt.show()

# Preparação dos dados
# Definindo as features e a variável alvo
X = data.drop(columns='is_ultra')
y = data['is_ultra']

# Divisão dos dados: 60% treino, 20% validação, 20% teste
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.4, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42)

# Inicializando e treinando os modelos base (sem ajuste de hiperparâmetros)
models = {
    "Logistic Regression": LogisticRegression(random_state=42, max_iter=1000),
    "Random Forest": RandomForestClassifier(random_state=42),
    "SVM": SVC(random_state=42)
}

# Treinando e validando os modelos base
validation_scores = {}

for model_name, model in models.items():
    # Treinando o modelo
    model.fit(X_train, y_train)

    # Fazendo previsões no conjunto de validação
    y_valid_pred = model.predict(X_valid)

    # Calculando a acurácia
    accuracy = accuracy_score(y_valid, y_valid_pred)
    validation_scores[model_name] = accuracy

    # Exibir as acurácias no conjunto de validação dos modelos base
print("Acurácias no conjunto de validação (modelos base):", validation_scores)

# Calibração de Hiperparâmetros com GridSearchCV para Random Forest
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Inicializando o modelo Random Forest
rf = RandomForestClassifier(random_state=42)

# Configurando o GridSearchCV
grid_search = GridSearchCV(
    estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Treinando o GridSearchCV
grid_search.fit(X_train, y_train)

# Melhor combinação de hiperparâmetros
print("Melhores hiperparâmetros:", grid_search.best_params_)

# Avaliação do melhor modelo no conjunto de validação
best_rf_model = grid_search.best_estimator_
y_valid_pred = best_rf_model.predict(X_valid)
valid_accuracy = accuracy_score(y_valid, y_valid_pred)
print("Acurácia no conjunto de validação após ajuste de hiperparâmetros:", valid_accuracy)

# Avaliação do modelo otimizado no conjunto de teste
y_test_pred = best_rf_model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_test_pred)
print("Acurácia no conjunto de teste após ajuste de hiperparâmetros:", test_accuracy)
